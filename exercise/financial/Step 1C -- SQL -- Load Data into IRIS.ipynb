{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vector Search with IRIS SQL\n",
    "This tutorial covers how to use InterSystems IRIS as vector storage for the same set of financial tweets that we loaded and vectorized in steps 1A and/or 1B."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Begin by running the block of code below, which imports the necessary components to get started."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sqlalchemy import create_engine, text\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will set InterSystems IRIS-specific information such as username, password, the hostname and port of the InterSystems IRIS container in this lab, the namespace, and a connection string putting all of those elements together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "username = 'demo'\n",
    "password = 'demo'\n",
    "hostname = os.getenv('IRIS_HOSTNAME', 'localhost')\n",
    "port = '55665' \n",
    "namespace = 'USER'\n",
    "CONNECTION_STRING = f\"iris://{username}:{password}@{hostname}:{port}/{namespace}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the the connection string we just built, let's establish a connection to InterSystems IRIS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine(CONNECTION_STRING)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load financial tweet data\n",
    "Next, we will load the JSON file with financial tweets into a Pandas DataFrame that can be easily imported into InterSystems IRIS as a SQL table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load JSONL file into DataFrame\n",
    "file_path = './data/financial/tweets_all.jsonl'\n",
    "df_tweets = pd.read_json(file_path, lines=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's display the first few rows of our DataFrame by running the line below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the new release of InterSystems IRIS vector search capability, InterSystems IRIS supports vectors as a datatype in tables! In the block below, we will create a table with a few different columns. The last column, 'note_vector', will be used to store vectors that are generated by passing the 'note' of a tweet through an embedding model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with engine.connect() as conn:\n",
    "    with conn.begin():# Load \n",
    "        sql = f\"\"\"\n",
    "                CREATE TABLE financial_tweets (\n",
    "        note VARCHAR(255),\n",
    "        note_vector VECTOR(DOUBLE, 384)\n",
    "        )\n",
    "                \"\"\"\n",
    "        result = conn.execute(text(sql))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's load a pre-trained sentence transformer model. This model's output vectors are of size 384. We will use this model to create vector embeddings for each financial tweet in our data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a pre-trained sentence transformer model. This model's output vectors are of size 384\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the sentence transformer above, we will create embeddings for all of the financial tweets in the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Generate embeddings for all tweets at once. Batch processing makes it faster\n",
    "embeddings = model.encode(df_tweets['note'].tolist(), normalize_embeddings=True)\n",
    "\n",
    "# Add the embeddings to the DataFrame\n",
    "df_tweets['note_vector'] = embeddings.tolist()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's view the first few entries again, this time with an added column for the vector embedding that goes with the tweet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next block of code, we will insert each tweet and its associated vector from the Pandas DataFrame into InterSystems IRIS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with engine.connect() as conn:\n",
    "    with conn.begin():\n",
    "        for index, row in df_tweets.iterrows():\n",
    "            sql = text(\"\"\"\n",
    "                INSERT INTO financial_tweets \n",
    "                (note, note_vector) \n",
    "                VALUES (:note, TO_VECTOR(:note_vector))\n",
    "            \"\"\")\n",
    "            conn.execute(sql, {\n",
    "                'note': row['note'], \n",
    "                'note_vector': str(row['note_vector'])\n",
    "            })\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's run a vector search! The block below will take a search phrase -- in this case, \"covid effect\" -- and convert it into a vector to be used in searching for similar content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "note_search = \"covid effect\"\n",
    "search_vector = model.encode(note_search, normalize_embeddings=True).tolist() # Convert search phrase into a vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will use the vector that was just created based on the search phrase and find the top three vectors that are closest in similarity to the vector for our \"covid effect\" search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with engine.connect() as conn:\n",
    "    with conn.begin():\n",
    "        sql = text(\"\"\"\n",
    "            SELECT TOP 3 * FROM financial_tweets\n",
    "            ORDER BY VECTOR_DOT_PRODUCT(note_vector, TO_VECTOR(:search_vector)) DESC\n",
    "        \"\"\")\n",
    "\n",
    "        results = conn.execute(sql, {'search_vector': str(search_vector)}).fetchall()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's print the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For an output that is a bit more readable, we can take the results and process them for better display using the block below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(results, columns=df_tweets.columns).iloc[:, :-1] # Remove vector\n",
    "pd.set_option('display.max_colwidth', None)  # Easier to read description\n",
    "results_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "treehacks",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
