{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vector Search with IRIS SQL\n",
    "This tutorial covers how to use InterSystems IRIS as vector storage for the same set of financial tweets that we loaded and vectorized in steps 1A and/or 1B."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Begin by running the block of code below, which imports the necessary components to get started."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/gs24ws/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os, pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sqlalchemy import create_engine, text\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will set InterSystems IRIS-specific information such as username, password, the hostname and port of the InterSystems IRIS container in this lab, the namespace, and a connection string putting all of those elements together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "username = 'demo'\n",
    "password = 'demo'\n",
    "hostname = os.getenv('IRIS_HOSTNAME', 'localhost')\n",
    "port = '55665' \n",
    "namespace = 'USER'\n",
    "CONNECTION_STRING = f\"iris://{username}:{password}@{hostname}:{port}/{namespace}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the the connection string we just built, let's establish a connection to InterSystems IRIS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine(CONNECTION_STRING)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load financial tweet data\n",
    "Next, we will load the JSON file with financial tweets into a Pandas DataFrame that can be easily imported into InterSystems IRIS as a SQL table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load JSONL file into DataFrame\n",
    "file_path = './data/financial/tweets_all.jsonl'\n",
    "df_tweets = pd.read_json(file_path, lines=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's display the first few rows of our DataFrame by running the line below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>note</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>$BYND - JPMorgan reels in expectations on Beyo...</td>\n",
       "      <td>2</td>\n",
       "      <td>https://huggingface.co/datasets/zeroshot/twitt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>$CCL $RCL - Nomura points to bookings weakness...</td>\n",
       "      <td>2</td>\n",
       "      <td>https://huggingface.co/datasets/zeroshot/twitt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>$CX - Cemex cut at Credit Suisse, J.P. Morgan ...</td>\n",
       "      <td>2</td>\n",
       "      <td>https://huggingface.co/datasets/zeroshot/twitt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>$ESS: BTIG Research cuts to Neutral https://t....</td>\n",
       "      <td>2</td>\n",
       "      <td>https://huggingface.co/datasets/zeroshot/twitt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>$FNKO - Funko slides after Piper Jaffray PT cu...</td>\n",
       "      <td>2</td>\n",
       "      <td>https://huggingface.co/datasets/zeroshot/twitt...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                note  sentiment  \\\n",
       "0  $BYND - JPMorgan reels in expectations on Beyo...          2   \n",
       "1  $CCL $RCL - Nomura points to bookings weakness...          2   \n",
       "2  $CX - Cemex cut at Credit Suisse, J.P. Morgan ...          2   \n",
       "3  $ESS: BTIG Research cuts to Neutral https://t....          2   \n",
       "4  $FNKO - Funko slides after Piper Jaffray PT cu...          2   \n",
       "\n",
       "                                                 url  \n",
       "0  https://huggingface.co/datasets/zeroshot/twitt...  \n",
       "1  https://huggingface.co/datasets/zeroshot/twitt...  \n",
       "2  https://huggingface.co/datasets/zeroshot/twitt...  \n",
       "3  https://huggingface.co/datasets/zeroshot/twitt...  \n",
       "4  https://huggingface.co/datasets/zeroshot/twitt...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tweets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the new release of InterSystems IRIS vector search capability, InterSystems IRIS supports vectors as a datatype in tables! In the block below, we will create a table with a few different columns. The last column, 'note_vector', will be used to store vectors that are generated by passing the 'note' of a tweet through an embedding model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "with engine.connect() as conn:\n",
    "    with conn.begin():# Load \n",
    "        sql = f\"\"\"\n",
    "                DROP TABLE IF EXISTS financial_tweets\n",
    "            \"\"\"\n",
    "        result = conn.execute(text(sql))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with engine.connect() as conn:\n",
    "    with conn.begin():# Load \n",
    "        sql = f\"\"\"\n",
    "                CREATE TABLE financial_tweets (\n",
    "        note VARCHAR(255),\n",
    "        sentiment INTEGER,\n",
    "        note_vector VECTOR(DOUBLE, 384)\n",
    "        )\n",
    "                \"\"\"\n",
    "        result = conn.execute(text(sql))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's load a pre-trained sentence transformer model. This model's output vectors are of size 384. We will use this model to create vector embeddings for each financial tweet in our data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a pre-trained sentence transformer model. This model's output vectors are of size 384\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the sentence transformer above, we will create embeddings for all of the financial tweets in the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Generate embeddings for all tweets at once. Batch processing makes it faster\n",
    "embeddings = model.encode(df_tweets['note'].tolist(), normalize_embeddings=True)\n",
    "\n",
    "# Add the embeddings to the DataFrame\n",
    "df_tweets['note_vector'] = embeddings.tolist()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's view the first few entries again, this time with an added column for the vector embedding that goes with the tweet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>note</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>url</th>\n",
       "      <th>note_vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>$BYND - JPMorgan reels in expectations on Beyo...</td>\n",
       "      <td>2</td>\n",
       "      <td>https://huggingface.co/datasets/zeroshot/twitt...</td>\n",
       "      <td>[-0.13631078600883484, 0.026333356276154518, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>$CCL $RCL - Nomura points to bookings weakness...</td>\n",
       "      <td>2</td>\n",
       "      <td>https://huggingface.co/datasets/zeroshot/twitt...</td>\n",
       "      <td>[-0.033777981996536255, 0.06702922284603119, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>$CX - Cemex cut at Credit Suisse, J.P. Morgan ...</td>\n",
       "      <td>2</td>\n",
       "      <td>https://huggingface.co/datasets/zeroshot/twitt...</td>\n",
       "      <td>[-0.08540519326925278, 0.04619771987199783, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>$ESS: BTIG Research cuts to Neutral https://t....</td>\n",
       "      <td>2</td>\n",
       "      <td>https://huggingface.co/datasets/zeroshot/twitt...</td>\n",
       "      <td>[-0.13111060857772827, 0.03535114973783493, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>$FNKO - Funko slides after Piper Jaffray PT cu...</td>\n",
       "      <td>2</td>\n",
       "      <td>https://huggingface.co/datasets/zeroshot/twitt...</td>\n",
       "      <td>[-0.0776449665427208, 0.055340882390737534, -0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                note  sentiment  \\\n",
       "0  $BYND - JPMorgan reels in expectations on Beyo...          2   \n",
       "1  $CCL $RCL - Nomura points to bookings weakness...          2   \n",
       "2  $CX - Cemex cut at Credit Suisse, J.P. Morgan ...          2   \n",
       "3  $ESS: BTIG Research cuts to Neutral https://t....          2   \n",
       "4  $FNKO - Funko slides after Piper Jaffray PT cu...          2   \n",
       "\n",
       "                                                 url  \\\n",
       "0  https://huggingface.co/datasets/zeroshot/twitt...   \n",
       "1  https://huggingface.co/datasets/zeroshot/twitt...   \n",
       "2  https://huggingface.co/datasets/zeroshot/twitt...   \n",
       "3  https://huggingface.co/datasets/zeroshot/twitt...   \n",
       "4  https://huggingface.co/datasets/zeroshot/twitt...   \n",
       "\n",
       "                                         note_vector  \n",
       "0  [-0.13631078600883484, 0.026333356276154518, -...  \n",
       "1  [-0.033777981996536255, 0.06702922284603119, -...  \n",
       "2  [-0.08540519326925278, 0.04619771987199783, 0....  \n",
       "3  [-0.13111060857772827, 0.03535114973783493, 0....  \n",
       "4  [-0.0776449665427208, 0.055340882390737534, -0...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tweets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next block of code, we will insert each tweet and its associated vector from the Pandas DataFrame into InterSystems IRIS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "with engine.connect() as conn:\n",
    "    with conn.begin():\n",
    "        for index, row in df_tweets.iterrows():\n",
    "            sql = text(\"\"\"\n",
    "                INSERT INTO financial_tweets \n",
    "                (note, sentiment, note_vector) \n",
    "                VALUES (:note, :sentiment, TO_VECTOR(:note_vector))\n",
    "            \"\"\")\n",
    "            conn.execute(sql, {\n",
    "                'note': row['note'], \n",
    "                'sentiment': row['sentiment'],\n",
    "                'note_vector': str(row['note_vector'])\n",
    "            })\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's run a vector search! The block below will take a search phrase -- in this case, \"covid effect\" -- and convert it into a vector to be used in searching for similar content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "note_search = \"covid effect\"\n",
    "search_vector = model.encode(note_search, normalize_embeddings=True).tolist() # Convert search phrase into a vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will use the vector that was just created based on the search phrase and find the top three vectors that are closest in similarity to the vector for our \"covid effect\" search.\n",
    "\n",
    "We are also specifying that the \"sentiment\" field be equal to 1, which in this dataset refers to \"positive sentiment\". This ability to use additional data to filter, directly in SQL, is a unique capability of InterSystems IRIS and how we have implemented our vector search functionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "with engine.connect() as conn:\n",
    "    with conn.begin():\n",
    "        sql = text(\"\"\"\n",
    "            SELECT TOP 3 * FROM financial_tweets\n",
    "            WHERE sentiment = 1\n",
    "            ORDER BY VECTOR_DOT_PRODUCT(note_vector, TO_VECTOR(:search_vector)) DESC\n",
    "        \"\"\")\n",
    "\n",
    "        results = conn.execute(sql, {'search_vector': str(search_vector)}).fetchall()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's print the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('$NVDA - Nvidia set for gaming tailwinds - BofA https://t.co/l3m78pJzrW', 1, 'https://huggingface.co/datasets/zeroshot/twitter-financial-news-sentiment', '-.020523741841316223144,.050246082246303558349,-.050210062414407730102,-.042630381882190704346,-.019571455195546150207,.0044612870551645755767,.02922 ... (8836 characters truncated) ... 79621,-.0025744738522917032241,-.042040660977363586426,.0043053296394646167756,-.062128648161888122558,-.020193470641970634461,.091304995119571685791'), (\"Morgan Stanley upgrades Nvidia to buy, predicting 2020 will be 'a return to solid growth' https://t.co/9gTGxKbSGj\", 1, 'https://huggingface.co/datasets/zeroshot/twitter-financial-news-sentiment', '-.074603758752346038818,-.046326998621225357056,-.0060204053297638893127,.030615020543336868286,.0050287107005715370178,.0047806329093873500823,-.047 ... (8826 characters truncated) ... 20913696,-.083879895508289337158,.042892597615718841552,.037991441786289215087,-.13488604128360748291,-.0014652515528723597526,.062368266284465789794'), ('Nvidia stock climbs after Morgan Stanley turns bullish', 1, 'https://huggingface.co/datasets/zeroshot/twitter-financial-news-sentiment', '-.036566156893968582153,-.079394064843654632568,-.012314003892242908477,.066461592912673950196,-.024784523993730545043,.0023135398514568805694,-.0301 ... (8824 characters truncated) ... 392532348,-.12754029035568237304,.054853908717632293701,-.021109972149133682251,-.16665665805339813232,-.017150241881608963012,.044106990098953247071')]\n"
     ]
    }
   ],
   "source": [
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For an output that is a bit more readable, we can take the results and process them for better display using the block below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>note</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>New developments added to @FedFRASER's COVID-19 timeline in the latest week: second historic rise in unemployment i… https://t.co/o4yYfNRbhA</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Central banks must evolve to help governments fight coronavirus https://t.co/mfSJuTKUDm</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Luckin Coffee and Yum China hit again by coronavirus anxiety</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                           note  \\\n",
       "0  New developments added to @FedFRASER's COVID-19 timeline in the latest week: second historic rise in unemployment i… https://t.co/o4yYfNRbhA   \n",
       "1                                                       Central banks must evolve to help governments fight coronavirus https://t.co/mfSJuTKUDm   \n",
       "2                                                                                  Luckin Coffee and Yum China hit again by coronavirus anxiety   \n",
       "\n",
       "  sentiment   url  \n",
       "0      None  None  \n",
       "1      None  None  \n",
       "2      None  None  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df = pd.DataFrame(results, columns=df_tweets.columns).iloc[:, :-1] # Remove vector\n",
    "pd.set_option('display.max_colwidth', None)  # Easier to read description\n",
    "results_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "treehacks",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
