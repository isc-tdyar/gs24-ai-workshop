{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combined Workshop\n",
    "\n",
    "1. Setup\n",
    "2. Loading Data Into IRIS\n",
    "3. Vector Search for Retrieval of Data\n",
    "4. Connecting to LLMs\n",
    "5. Debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0b5c6b1921a4dae8e3216b589da784a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 3 files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "##############################################################\n",
    "## This code is for academic and educational purposes only. ##\n",
    "## Event: Global Summit 2024 Maryland USA                   ##\n",
    "## InterSystems Corporation 2024 (C)                        ##\n",
    "## Date: June 9th 2024                                      ##\n",
    "##############################################################\n",
    "\n",
    "\n",
    "## Use the Huggingface hub library to download data effectively\n",
    "from huggingface_hub import snapshot_download, hf_hub_download\n",
    "\n",
    "#####\n",
    "## Here is our dastaset \"tag\", these are formatted in the <account>/<data-set-name> format\n",
    "## Here is the direct link this points to\n",
    "# https://huggingface.co/datasets/TimKoornstra/financial-tweets-sentiment\n",
    "financial_dataset = 'TimKoornstra/financial-tweets-sentiment'\n",
    "#####\n",
    "\n",
    "# Do the download\n",
    "directory = snapshot_download(repo_id=financial_dataset, local_dir='./data/financial', repo_type=\"dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc40765ddc7b4fb5a96c88b4f1bdc0db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "financial_tweets = load_dataset(\"parquet\", data_files='./data/financial/data/train-00000-of-00001.parquet')\n",
    "# healthcare_notes = load_dataset(\"json\", data_files='./data/healthcare/augmented_notes_30K.jsonl')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['tweet', 'sentiment', 'url'],\n",
       "        num_rows: 38091\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "financial_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### To see what the dataset looks like you see there are 30000 rows\n",
    "## >> That's a lot, so you might want to trim it down\n",
    "## >> let's trim this down to just tweets\n",
    "notes = [{'note': note} for note in financial_tweets['train']['tweet'][:1000]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'note': '$BYND - JPMorgan reels in expectations on Beyond Meat https://t.co/bd0xbFGjkT'},\n",
       " {'note': '$CCL $RCL - Nomura points to bookings weakness at Carnival and Royal Caribbean https://t.co/yGjpT2ReD3'}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "notes[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explanation of previous block\n",
    "\n",
    "In summary, this code loads two datasets: one from a Parquet file containing financial tweets and another from a JSON Lines file containing healthcare notes. The loaded datasets are stored in the financial_tweets and healthcare_notes variables, respectively, and can be further processed or analyzed using the datasets library or other Python libraries\n",
    "\n",
    "This Python code is loading two datasets using the datasets library, which is a popular library for working with datasets in Python. Here's a breakdown of what each line does:\n",
    "\n",
    "Line 1: from datasets import load_dataset\n",
    "\n",
    "This line imports the load_dataset function from the datasets library. This function is used to load datasets from various sources, such as files or online repositories.\n",
    "Line 2: financial_tweets = load_dataset(\"parquet\", data_files='./data/financial/data/train-00000-of-00001.parquet')\n",
    "\n",
    "This line loads a dataset from a Parquet file located at ./data/financial/data/train-00000-of-00001.parquet.\n",
    "The load_dataset function takes two arguments:\n",
    "The first argument, \"parquet\", specifies the format of the dataset file. In this case, it's a Parquet file, which is a columnar storage format for large datasets.\n",
    "The data_files argument specifies the path to the dataset file.\n",
    "The loaded dataset is assigned to a variable named financial_tweets.\n",
    "Line 3: healthcare_notes = load_dataset(\"json\", data_files='./data/healthcare/augmented_notes_30K.jsonl')\n",
    "\n",
    "This line loads a dataset from a JSON Lines file located at ./data/healthcare/augmented_notes_30K.jsonl.\n",
    "Again, the load_dataset function takes two arguments:\n",
    "The first argument, \"json\", specifies the format of the dataset file. In this case, it's a JSON Lines file, which is a text-based format for storing JSON data.\n",
    "The data_files argument specifies the path to the dataset file.\n",
    "The loaded dataset is assigned to a variable named healthcare_notes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jsonlines\n",
    "\n",
    "with jsonlines.open('./data/financial/tweets_all.jsonl', mode='w') as writer:\n",
    "    writer.write_all(notes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
