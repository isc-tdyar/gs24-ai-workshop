{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Advanced Vector Storage Options\n",
    "\n",
    "> As a reminder, we can create a vector store in python using llama_index like so:\n",
    "\n",
    "```py\n",
    "vector_store = IRISVectorStore.from_params(\n",
    "    connection_string=CONNECTION_STRING,\n",
    "    table_name=\"augmented_notes\",\n",
    "    embed_dim=1536,  # openai embedding dimension\n",
    ")\n",
    "```\n",
    "\n",
    "But we may need a few different tweaks depending on how we'd like to store our data\n",
    "* `table_name`: IRIS Table to store the vectors in. This should be set so you keep data separate and can come back to this store in other contexts\n",
    "* `embed_dim`: Size of embedding. Different models have different lengths, and generally there are different embedding models for different use cases. \n",
    "  * For example: OpenAI uses 1536 vectors, common open source models use 1024\n",
    "  * This setting is dependent on how you vector-ize your data\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Querying with filtering\n",
    "\n",
    "You may also want to filter your data based on other metadata in your table or vector store.\n",
    "\n",
    "Some options you have:\n",
    "* Filtering on additional fields in the table\n",
    "* Using separate tables\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
