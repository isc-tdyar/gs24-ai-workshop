{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 0 (Not required for Global Summit Exercise)\n",
    "\n",
    "* Step 0 reviews how to get the data into a local environment. \n",
    "* Here we'll download a public data set for usage\n",
    "\n",
    "### Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The next block is utilizing the Hugging Face dataset library to download an open-source clinical note dataset, which will be used for for vectorizing. \n",
    "* This dataset, contains a large collection of annotated clinical notes that will help our model learn to extract relevant information. \n",
    "* Hugging Face is a popular open-source AI company that provides a wide range of NLP tools and datasets, enabling developers to easily access and integrate high-quality language models and datasets into their projects.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 7 files: 100%|██████████| 7/7 [00:00<00:00, 23.43it/s]\n"
     ]
    }
   ],
   "source": [
    "##############################################################\n",
    "## This code is for academic and educational purposes only. ##\n",
    "## Event: Global Summit 2024 Maryland USA                   ##\n",
    "## InterSystems Corporation 2024 (C)                        ##\n",
    "## Date: June 9th 2024                                      ##\n",
    "##############################################################\n",
    "\n",
    "\n",
    "## Use the Huggingface hub library to download data effectively\n",
    "from huggingface_hub import snapshot_download, hf_hub_download\n",
    "\n",
    "#####\n",
    "## Here is our dastaset \"tag\", these are formatted in the <account>/<data-set-name> format\n",
    "## Here is the direct link this points to\n",
    "# https://huggingface.co/datasets/AGBonnet/augmented-clinical-notes\n",
    "healthcare_dataset = 'AGBonnet/augmented-clinical-notes'\n",
    "#####\n",
    "\n",
    "#####\n",
    "# Here the snapshot download function downloads a copy of the data to a local directory\n",
    "directory = snapshot_download(repo_id=healthcare_dataset, local_dir='./data/healthcare', repo_type=\"dataset\")\n",
    "#####\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1e1de173972466c8b9e3b13b964c80b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "##############################################################\n",
    "## This code is for academic and educational purposes only. ##\n",
    "## Event: Global Summit 2024 Maryland USA                   ##\n",
    "## InterSystems Corporation 2024 (C)                        ##\n",
    "## Date: June 9th 2024                                      ##\n",
    "##############################################################\n",
    "\n",
    "#####\n",
    "## Huggingface provides a \"datasets\" library that lets you load datasets quite easily\n",
    "## We'll use load dataset\n",
    "from datasets import load_dataset\n",
    "#####\n",
    "\n",
    "#### To load a saved dataset and use it, you can call the load_dataset from a file\n",
    "## Here, we load the dataset in json format.\n",
    "healthcare_notes = load_dataset(\"json\", data_files='./data/healthcare/augmented_notes_30K.jsonl')\n",
    "##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### To see what the dataset looks like you see there are 30000 rows\n",
    "## >> That's a lot, so you might want to trim it down\n",
    "## >> let's trim this down to just notes\n",
    "\n",
    "notes = [{'note': note} for note in healthcare_notes['train']['note'][:1000]]\n",
    "\n",
    "#####\n",
    "## >>\n",
    "## >>\n",
    "# notes\n",
    "# healthcare_notes['train'][0]\n",
    "#####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jsonlines\n",
    "\n",
    "with jsonlines.open('./data/healthcare/augmented_notes_1000.jsonl', mode='w') as writer:\n",
    "    writer.write_all(notes)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
